{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/20kee/Desktop/programming/Language/python/boxhead-reinforcement-learning/yolov5\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/20kee/Desktop/programming/Language/python/boxhead-reinforcement-learning\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/20kee/Desktop/programming/Language/python/boxhead-reinforcement-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   910  100   910    0     0   2290      0 --:--:-- --:--:-- --:--:--  2292\n",
      "100 2056k  100 2056k    0     0   934k      0  0:00:02  0:00:02 --:--:-- 1463k\n",
      "Archive:  roboflow.zip\n",
      " extracting: README.dataset.txt      \n",
      " extracting: README.roboflow.txt     \n",
      " extracting: data.yaml               \n",
      "   creating: test/\n",
      "   creating: test/images/\n",
      " extracting: test/images/33_png.rf.1c5745d1c593785b5da3d82376502b5d.jpg  \n",
      " extracting: test/images/50_png.rf.7cdcaab7c938b84987785248ab0278e2.jpg  \n",
      " extracting: test/images/5_png.rf.4d024056952bc341704df6637401e60c.jpg  \n",
      " extracting: test/images/82_png.rf.9fcc4831c2286a3983db06c67f68f606.jpg  \n",
      " extracting: test/images/84_png.rf.54e98dc172ff8c4aac0b30ef2dac4a30.jpg  \n",
      " extracting: test/images/86_png.rf.458ad09e1ac6864f4733a71571edb4e2.jpg  \n",
      "   creating: test/labels/\n",
      " extracting: test/labels/33_png.rf.1c5745d1c593785b5da3d82376502b5d.txt  \n",
      " extracting: test/labels/50_png.rf.7cdcaab7c938b84987785248ab0278e2.txt  \n",
      " extracting: test/labels/5_png.rf.4d024056952bc341704df6637401e60c.txt  \n",
      " extracting: test/labels/82_png.rf.9fcc4831c2286a3983db06c67f68f606.txt  \n",
      " extracting: test/labels/84_png.rf.54e98dc172ff8c4aac0b30ef2dac4a30.txt  \n",
      " extracting: test/labels/86_png.rf.458ad09e1ac6864f4733a71571edb4e2.txt  \n",
      "   creating: train/\n",
      "   creating: train/images/\n",
      " extracting: train/images/100_png.rf.ebd6cddeb6550f7cb313fc5a4e57c743.jpg  \n",
      " extracting: train/images/102_png.rf.00a601a6c0b71203d6626e8916eb5b28.jpg  \n",
      " extracting: train/images/113_png.rf.2103ce10019aaae2590425ceb6838e09.jpg  \n",
      " extracting: train/images/117_png.rf.86ad6f42247531304c26e8159d529b5a.jpg  \n",
      " extracting: train/images/118_png.rf.9de48992f821c70cc0e44eda6b0f19dd.jpg  \n",
      " extracting: train/images/13_png.rf.40f2ec5cc5f2b2516e8813eee9cba862.jpg  \n",
      " extracting: train/images/15_png.rf.291ea21f8862acd684ceb5d7b7f80205.jpg  \n",
      " extracting: train/images/1_png.rf.494a56bf69ce787d37b43e4658da6704.jpg  \n",
      " extracting: train/images/29_png.rf.b58c07d9dfb175e64ba58a7719148121.jpg  \n",
      " extracting: train/images/3_png.rf.f4656d07250276b13d981ddd2fd2b23a.jpg  \n",
      " extracting: train/images/40_png.rf.d5a768174cca8999e83019cd04d149a5.jpg  \n",
      " extracting: train/images/42_png.rf.bd392919deaf05b82299340bf61f3e7b.jpg  \n",
      " extracting: train/images/43_png.rf.3d71a1877e5a7646505d50b05d363017.jpg  \n",
      " extracting: train/images/44_png.rf.ad2d8b4b83f349df69fca820adf3a6fd.jpg  \n",
      " extracting: train/images/45_png.rf.e6a95af9482865458b41195ac9420bd1.jpg  \n",
      " extracting: train/images/46_png.rf.2210cbfab8441a753def16f7504b1915.jpg  \n",
      " extracting: train/images/51_png.rf.777e3969294434f6780c621ad1c8de56.jpg  \n",
      " extracting: train/images/52_png.rf.41fb56f12a3f60bf50bc0d406a5123d9.jpg  \n",
      " extracting: train/images/53_png.rf.3d68a5b4ac5fb5f1e1aeac983a63a438.jpg  \n",
      " extracting: train/images/55_png.rf.b2de070048d56241f187bf0a1f75dacb.jpg  \n",
      " extracting: train/images/57_png.rf.2bb03bb18c6b0c649363cec27f9d3cd0.jpg  \n",
      " extracting: train/images/68_png.rf.ab55adb543103bf45a9dfc396eb8bac6.jpg  \n",
      " extracting: train/images/6_png.rf.76faaca44ff9b36a46606fa0456a2856.jpg  \n",
      " extracting: train/images/78_png.rf.bcb95041561e6429e0897cae346104da.jpg  \n",
      " extracting: train/images/79_png.rf.5b7b97fb2c9617a232a49ed5cefe7c6f.jpg  \n",
      " extracting: train/images/7_png.rf.26f8b6943cb9539cc8c2f42fbddb6636.jpg  \n",
      " extracting: train/images/80_png.rf.1817aabd5335d4e262b016ec02d8c473.jpg  \n",
      " extracting: train/images/83_png.rf.a895784a0faae6fec035fda80ca3e63b.jpg  \n",
      " extracting: train/images/85_png.rf.3869e3a303b0a8977abb123d9d5924d7.jpg  \n",
      " extracting: train/images/87_png.rf.1631d9ad65ed2a2fade2f409a72ebefe.jpg  \n",
      " extracting: train/images/90_png.rf.d5d244cb86aac3fe3a2864bcfc18a901.jpg  \n",
      " extracting: train/images/92_png.rf.1c0336880b2c6228eee4059c0d43c6c7.jpg  \n",
      " extracting: train/images/93_png.rf.c494b51e0da4db68e406f876cb1e7a0f.jpg  \n",
      " extracting: train/images/94_png.rf.e1116792710238c7bec7d4a643d96880.jpg  \n",
      " extracting: train/images/97_png.rf.5e11495ff09af8912ff66ec411348d50.jpg  \n",
      " extracting: train/images/bossleft_png.rf.9ae03f24a0eb733fa312d13d2fbbf6c2.jpg  \n",
      " extracting: train/images/boxhead_png.rf.486ea25c0b9166f43e2bfa95ac29c1b7.jpg  \n",
      " extracting: train/images/down_png.rf.158e65a2943326ba4ca16e81c496faf6.jpg  \n",
      " extracting: train/images/game1_png.rf.ab8b9d1bf5e77f2b188bf5c5745f6b5f.jpg  \n",
      " extracting: train/images/game3_png.rf.4ab132a5017481de53b585269d188bbc.jpg  \n",
      " extracting: train/images/left_png.rf.d096ab25db448352b199af07cc6f85bc.jpg  \n",
      " extracting: train/images/leftdown_png.rf.15e15345f0008eaab24a0930d00fa905.jpg  \n",
      " extracting: train/images/leftup_png.rf.9a7175c6cdbc089972d04ac79abdb9d5.jpg  \n",
      " extracting: train/images/retry_png.rf.3258ad3704ca945147a36eac15ce59c3.jpg  \n",
      " extracting: train/images/right_png.rf.c9e0d25d64b674fa26f12d31593a5d04.jpg  \n",
      " extracting: train/images/rightdown_png.rf.7cf5f93c93161a5c3ec3922f847a202e.jpg  \n",
      " extracting: train/images/rightup_png.rf.b91006a910b872967270081788e21d21.jpg  \n",
      " extracting: train/images/up_png.rf.ff8b6510bbad02cec7654797c02df11b.jpg  \n",
      "   creating: train/labels/\n",
      " extracting: train/labels/100_png.rf.ebd6cddeb6550f7cb313fc5a4e57c743.txt  \n",
      " extracting: train/labels/102_png.rf.00a601a6c0b71203d6626e8916eb5b28.txt  \n",
      " extracting: train/labels/113_png.rf.2103ce10019aaae2590425ceb6838e09.txt  \n",
      " extracting: train/labels/117_png.rf.86ad6f42247531304c26e8159d529b5a.txt  \n",
      " extracting: train/labels/118_png.rf.9de48992f821c70cc0e44eda6b0f19dd.txt  \n",
      " extracting: train/labels/13_png.rf.40f2ec5cc5f2b2516e8813eee9cba862.txt  \n",
      " extracting: train/labels/15_png.rf.291ea21f8862acd684ceb5d7b7f80205.txt  \n",
      " extracting: train/labels/1_png.rf.494a56bf69ce787d37b43e4658da6704.txt  \n",
      " extracting: train/labels/29_png.rf.b58c07d9dfb175e64ba58a7719148121.txt  \n",
      " extracting: train/labels/3_png.rf.f4656d07250276b13d981ddd2fd2b23a.txt  \n",
      " extracting: train/labels/40_png.rf.d5a768174cca8999e83019cd04d149a5.txt  \n",
      " extracting: train/labels/42_png.rf.bd392919deaf05b82299340bf61f3e7b.txt  \n",
      " extracting: train/labels/43_png.rf.3d71a1877e5a7646505d50b05d363017.txt  \n",
      " extracting: train/labels/44_png.rf.ad2d8b4b83f349df69fca820adf3a6fd.txt  \n",
      " extracting: train/labels/45_png.rf.e6a95af9482865458b41195ac9420bd1.txt  \n",
      " extracting: train/labels/46_png.rf.2210cbfab8441a753def16f7504b1915.txt  \n",
      " extracting: train/labels/51_png.rf.777e3969294434f6780c621ad1c8de56.txt  \n",
      " extracting: train/labels/52_png.rf.41fb56f12a3f60bf50bc0d406a5123d9.txt  \n",
      " extracting: train/labels/53_png.rf.3d68a5b4ac5fb5f1e1aeac983a63a438.txt  \n",
      " extracting: train/labels/55_png.rf.b2de070048d56241f187bf0a1f75dacb.txt  \n",
      " extracting: train/labels/57_png.rf.2bb03bb18c6b0c649363cec27f9d3cd0.txt  \n",
      " extracting: train/labels/68_png.rf.ab55adb543103bf45a9dfc396eb8bac6.txt  \n",
      " extracting: train/labels/6_png.rf.76faaca44ff9b36a46606fa0456a2856.txt  \n",
      " extracting: train/labels/78_png.rf.bcb95041561e6429e0897cae346104da.txt  \n",
      " extracting: train/labels/79_png.rf.5b7b97fb2c9617a232a49ed5cefe7c6f.txt  \n",
      " extracting: train/labels/7_png.rf.26f8b6943cb9539cc8c2f42fbddb6636.txt  \n",
      " extracting: train/labels/80_png.rf.1817aabd5335d4e262b016ec02d8c473.txt  \n",
      " extracting: train/labels/83_png.rf.a895784a0faae6fec035fda80ca3e63b.txt  \n",
      " extracting: train/labels/85_png.rf.3869e3a303b0a8977abb123d9d5924d7.txt  \n",
      " extracting: train/labels/87_png.rf.1631d9ad65ed2a2fade2f409a72ebefe.txt  \n",
      " extracting: train/labels/90_png.rf.d5d244cb86aac3fe3a2864bcfc18a901.txt  \n",
      " extracting: train/labels/92_png.rf.1c0336880b2c6228eee4059c0d43c6c7.txt  \n",
      " extracting: train/labels/93_png.rf.c494b51e0da4db68e406f876cb1e7a0f.txt  \n",
      " extracting: train/labels/94_png.rf.e1116792710238c7bec7d4a643d96880.txt  \n",
      " extracting: train/labels/97_png.rf.5e11495ff09af8912ff66ec411348d50.txt  \n",
      " extracting: train/labels/bossleft_png.rf.9ae03f24a0eb733fa312d13d2fbbf6c2.txt  \n",
      " extracting: train/labels/boxhead_png.rf.486ea25c0b9166f43e2bfa95ac29c1b7.txt  \n",
      " extracting: train/labels/down_png.rf.158e65a2943326ba4ca16e81c496faf6.txt  \n",
      " extracting: train/labels/game1_png.rf.ab8b9d1bf5e77f2b188bf5c5745f6b5f.txt  \n",
      " extracting: train/labels/game3_png.rf.4ab132a5017481de53b585269d188bbc.txt  \n",
      " extracting: train/labels/left_png.rf.d096ab25db448352b199af07cc6f85bc.txt  \n",
      " extracting: train/labels/leftdown_png.rf.15e15345f0008eaab24a0930d00fa905.txt  \n",
      " extracting: train/labels/leftup_png.rf.9a7175c6cdbc089972d04ac79abdb9d5.txt  \n",
      " extracting: train/labels/retry_png.rf.3258ad3704ca945147a36eac15ce59c3.txt  \n",
      " extracting: train/labels/right_png.rf.c9e0d25d64b674fa26f12d31593a5d04.txt  \n",
      " extracting: train/labels/rightdown_png.rf.7cf5f93c93161a5c3ec3922f847a202e.txt  \n",
      " extracting: train/labels/rightup_png.rf.b91006a910b872967270081788e21d21.txt  \n",
      " extracting: train/labels/up_png.rf.ff8b6510bbad02cec7654797c02df11b.txt  \n",
      "   creating: valid/\n",
      "   creating: valid/images/\n",
      " extracting: valid/images/116_png.rf.e6223427ddf20c60c6d75f7021f21469.jpg  \n",
      " extracting: valid/images/17_png.rf.856a9e1b372ced4c7ee308428a1b0c97.jpg  \n",
      " extracting: valid/images/27_png.rf.5d49b09243eb50bbfd519e74f47d8879.jpg  \n",
      " extracting: valid/images/2_png.rf.384728178fed3194f2761099c49aacc3.jpg  \n",
      " extracting: valid/images/31_png.rf.57a20f35d3393b20cdc6b75305c077ce.jpg  \n",
      " extracting: valid/images/47_png.rf.d25d09206dd973d4e6bf6ccefa967038.jpg  \n",
      " extracting: valid/images/54_png.rf.37bda952f4f6e659aca8e0e8cca94ab3.jpg  \n",
      " extracting: valid/images/91_png.rf.d44e79c9984758aab31d9dccf53444bc.jpg  \n",
      " extracting: valid/images/96_png.rf.0aa5a1a26e458508510bed367b013ef3.jpg  \n",
      "   creating: valid/labels/\n",
      " extracting: valid/labels/116_png.rf.e6223427ddf20c60c6d75f7021f21469.txt  \n",
      " extracting: valid/labels/17_png.rf.856a9e1b372ced4c7ee308428a1b0c97.txt  \n",
      " extracting: valid/labels/27_png.rf.5d49b09243eb50bbfd519e74f47d8879.txt  \n",
      " extracting: valid/labels/2_png.rf.384728178fed3194f2761099c49aacc3.txt  \n",
      " extracting: valid/labels/31_png.rf.57a20f35d3393b20cdc6b75305c077ce.txt  \n",
      " extracting: valid/labels/47_png.rf.d25d09206dd973d4e6bf6ccefa967038.txt  \n",
      " extracting: valid/labels/54_png.rf.37bda952f4f6e659aca8e0e8cca94ab3.txt  \n",
      " extracting: valid/labels/91_png.rf.d44e79c9984758aab31d9dccf53444bc.txt  \n",
      " extracting: valid/labels/96_png.rf.0aa5a1a26e458508510bed367b013ef3.txt  \n"
     ]
    }
   ],
   "source": [
    "!curl -L \"https://app.roboflow.com/ds/YR192DLLsH?key=XeEmxjxiUG\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/20kee/Desktop/programming/Language/python/boxhead-reinforcement-learning/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/yolov5s.yaml, data=../data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=415, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=boxhead_model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 üöÄ 2024-5-12 Python-3.11.2 torch-2.3.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=13\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     48546  models.yolo.Detect                      [13, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7054690 parameters, 7054690 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "WARNING ‚ö†Ô∏è --img-size 415 must be multiple of max stride 32, updating to 416\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/20kee/Desktop/programming/Language/python/boxhead-reinfor\u001b[0m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/20kee/Desktop/programming/Language/python/boxhead-reinfor\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/20kee/Desktop/programming/Language/python/boxhead-reinforcement-learning/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/20kee/Desktop/programming/Language/python/boxhead-reinforce\u001b[0m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/20kee/Desktop/programming/Language/python/boxhead-reinforce\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/20kee/Desktop/programming/Language/python/boxhead-reinforcement-learning/valid/labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.75 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to runs/train/boxhead_model/labels.jpg... \n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/boxhead_model\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "       0/49         0G     0.1339    0.01666    0.07658         45        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49         0G     0.1039     0.0162    0.05994         61        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49         0G       0.13    0.01569    0.07318         46        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49         0G     0.1123    0.01797     0.0635         47        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49         0G     0.1073    0.02039     0.0614         51        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49         0G      0.108    0.02003    0.06188         54        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49         0G      0.106    0.02129     0.0607         45        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00204     0.0714     0.0013   0.000182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49         0G     0.1238    0.02065     0.0667         57        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16   0.000661     0.0357    0.00039    3.9e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49         0G     0.1053    0.01942    0.05812         51        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49         0G     0.1119    0.02537    0.06254         67        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49         0G    0.08606    0.02305    0.04878         66        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00155     0.0714    0.00119   0.000409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49         0G    0.09951    0.02157    0.05242         60        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16   0.000962     0.0357    0.00063   0.000189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49         0G    0.09702    0.02138     0.0522         56        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00253      0.107    0.00188   0.000411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49         0G    0.08446    0.02086    0.04501         47        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00368      0.214    0.00827    0.00181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49         0G    0.08552    0.02493    0.04953         64        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00526      0.393     0.0109    0.00425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49         0G    0.09283    0.02245    0.04426         38        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00328       0.25    0.00442    0.00115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49         0G    0.09412    0.02452    0.04483         39        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00399      0.393     0.0113     0.0023\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49         0G    0.08248    0.02152    0.05204         68        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00369      0.393     0.0172    0.00441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49         0G    0.08393    0.02162    0.04235         54        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00487        0.5     0.0307    0.00839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49         0G    0.07791     0.0209     0.0397         58        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00471        0.5     0.0483    0.00792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49         0G    0.08819    0.02217    0.04194         60        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00457        0.5     0.0752      0.019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49         0G    0.07557    0.02066    0.03818         45        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00421        0.5      0.011    0.00355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49         0G    0.07181    0.01859    0.03891         43        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00554       0.75     0.0669     0.0182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49         0G    0.06787    0.02079    0.04001         62        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00386        0.5     0.0246    0.00812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49         0G    0.08099    0.02273    0.04524         44        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16    0.00675        0.5       0.03    0.00929\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49         0G     0.0904    0.02541    0.05145         54        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.512       0.25     0.0532     0.0154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49         0G    0.06255     0.0227    0.03795         52        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.517       0.25     0.0505     0.0159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49         0G    0.06349    0.02225    0.03708         64        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.283      0.214     0.0288     0.0105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49         0G    0.07006    0.01878    0.03538         49        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.283      0.214     0.0288     0.0105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49         0G    0.09779    0.02352    0.04545         67        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.285       0.25     0.0457     0.0148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49         0G    0.05769    0.02066    0.03806         32        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.289      0.248     0.0563     0.0187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49         0G    0.06643    0.02193    0.03982         32        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.279      0.321     0.0439     0.0151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49         0G    0.06471    0.01851    0.03538         35        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.279      0.321     0.0439     0.0151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49         0G    0.07706    0.02123    0.04756         47        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.287      0.393     0.0698     0.0229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49         0G    0.08106    0.02117    0.05078         42        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16       0.54      0.179      0.079     0.0258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49         0G     0.0634    0.01907    0.03416         55        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.293      0.321      0.116     0.0317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49         0G    0.07162    0.02133    0.04178         55        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.293      0.321      0.116     0.0317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49         0G    0.05405    0.01931    0.03857         33        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.561      0.321      0.151     0.0574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49         0G    0.06135     0.0205    0.03334         70        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.573      0.321      0.149     0.0616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49         0G    0.06127     0.0195    0.03843         56        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.628      0.321      0.164     0.0727\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49         0G     0.0709    0.01891    0.04346         50        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.628      0.321      0.164     0.0727\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49         0G    0.05989      0.024    0.03541         75        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.624      0.321      0.168     0.0755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49         0G    0.07483    0.02133    0.04724         53        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.636      0.321      0.185     0.0798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49         0G    0.07374    0.01756    0.04766         50        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.619      0.286      0.177     0.0788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49         0G    0.07376    0.01715    0.04522         59        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.619      0.286      0.177     0.0788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49         0G    0.06777    0.02201     0.0374         43        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.615      0.321      0.184     0.0842\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49         0G    0.06387    0.01708    0.04885         38        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16       0.62      0.321      0.173     0.0813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49         0G    0.05643    0.01791    0.03953         46        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.624      0.321      0.165     0.0783\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49         0G    0.06149       0.02    0.04277         45        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.624      0.321      0.165     0.0783\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49         0G    0.05772    0.01867    0.03483         54        416: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.627      0.321      0.175     0.0808\n",
      "\n",
      "50 epochs completed in 0.203 hours.\n",
      "Optimizer stripped from runs/train/boxhead_model/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from runs/train/boxhead_model/weights/best.pt, 14.4MB\n",
      "\n",
      "Validating runs/train/boxhead_model/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7045186 parameters, 0 gradients, 15.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9         16      0.615      0.321      0.173     0.0796\n",
      "                 agent          9          7      0.316      0.429      0.438      0.193\n",
      "                  ball          9          1          1          0          0          0\n",
      "                  boss          9          1          1          0     0.0293    0.00988\n",
      "                jombie          9          7      0.145      0.857      0.225      0.116\n",
      "Results saved to \u001b[1mruns/train/boxhead_model\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/bin/python3 train.py --img 415 --batch 16 --epochs 50 --data ../data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name boxhead_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/20kee/Desktop/programming/Language/python/boxhead-reinforcement-learning/yolov5\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./runs/train/boxhead_model/weights/best.pt'], source=../train/images/15_png.rf.291ea21f8862acd684ceb5d7b7f80205.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ 2024-5-12 Python-3.11.2 torch-2.3.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7045186 parameters, 0 gradients, 15.9 GFLOPs\n",
      "image 1/1 /Users/20kee/Desktop/programming/Language/python/boxhead-reinforcement-learning/train/images/15_png.rf.291ea21f8862acd684ceb5d7b7f80205.jpg: 640x640 (no detections), 138.3ms\n",
      "Speed: 0.5ms pre-process, 138.3ms inference, 0.3ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/bin/python3 detect.py --weights ./runs/train/boxhead_model/weights/best.pt --conf 0.5 --source ../train/images/15_png.rf.291ea21f8862acd684ceb5d7b7f80205.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
